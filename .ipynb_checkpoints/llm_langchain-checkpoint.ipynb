{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc42abf-bc65-46d1-867b-e67f272ebb57",
   "metadata": {},
   "source": [
    "# Deep Dive into LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45ac14ac-e977-4976-82af-4444ee12f3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95bea6ba-a907-49c2-9f76-e70d2d13240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.27.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: /home/rasyidannas/anaconda3/lib/python3.11/site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: langchain-openai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dc81a-482b-4b49-a2b6-309eeca85c71",
   "metadata": {},
   "source": [
    "## Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fa352af-977a-4ebc-a15d-a1061510c905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eff54ea-689b-4519-8488-11bb7d84b441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is the branch of physics that describes the behavior of particles at the smallest scales, where physical properties such as position, momentum, and energy are quantized into discrete units.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke('Explain quantum mechanics in one sentence.', model='gpt-3.5-turbo')\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0c9b3f-b939-47d2-aa19-0a195f0b3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for show detail our configuration CHatOpenAI\n",
    "# help(ChatOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "057789d5-8462-4291-89b7-3aed305a6e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisika kuantum adalah cabang ilmu fisika yang mempelajari perilaku partikel-partikel sangat kecil seperti atom dan foton.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in Indonesian'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ca732-5172-48fb-9530-1d880cdf3767",
   "metadata": {},
   "source": [
    "## Caching LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dff1a8-6b4a-4d7a-963d-90e4b4e8f085",
   "metadata": {},
   "source": [
    "### In-Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c051cecb-be7a-4785-8573-e97f459089a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea76d751-4171-4d07-8fff-b2970195f68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 68.2 ms, total: 488 ms\n",
      "Wall time: 2.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the cookie go to the doctor?\\n\\nBecause it was feeling crumbly!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import  InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = 'Tell me a joke that a toddler can understand'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0326b3b9-bbde-4350-be15-091e71d28a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 577 µs, sys: 59 µs, total: 636 µs\n",
      "Wall time: 646 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the cookie go to the doctor?\\n\\nBecause it was feeling crumbly!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882799f-536b-4cbd-a4db-203f3ff3158d",
   "metadata": {},
   "source": [
    "### SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d3b08b-266f-41de-952a-4a93374a6dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path='.langchain.db'))\n",
    "\n",
    "# First request (not in cahce, takes Longer)\n",
    "llm.invoke('Tell me a joke')\n",
    "\n",
    "# Second request (cached, faster)\n",
    "llm.invoke('Tell me a joke')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28688c8-d7d8-4adb-969d-4d83497ce607",
   "metadata": {},
   "source": [
    "### LLM Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a007571-2103-4330-9539-5ed8e8efa00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "Beneath the pale moonlight\n",
      "A raven takes flight\n",
      "Its shadow dancing on the ground\n",
      "As it lets out a haunting sound\n",
      "\n",
      "Chorus:\n",
      "Oh, Moon and Raven\n",
      "In the night, we'll be brave and\n",
      "Together we'll soar\n",
      "Forevermore, forevermore\n",
      "\n",
      "Verse 2:\n",
      "The moon's silver glow\n",
      "Guides the raven's flow\n",
      "Through the starry sky\n",
      "As they both reach new highs\n",
      "\n",
      "Chorus:\n",
      "Oh, Moon and Raven\n",
      "In the night, we'll be brave and\n",
      "Together we'll soar\n",
      "Forevermore, forevermore\n",
      "\n",
      "Bridge:\n",
      "In the darkness, they find solace\n",
      "Each other's company a promise\n",
      "To always be there, to never let go\n",
      "In the night, they'll always know\n",
      "\n",
      "Chorus:\n",
      "Oh, Moon and Raven\n",
      "In the night, we'll be brave and\n",
      "Together we'll soar\n",
      "Forevermore, forevermore\n",
      "\n",
      "Outro:\n",
      "As the moon fades away\n",
      "And the dawn starts a new day\n",
      "The raven and the moon remain\n",
      "Bound together, in the night they'll reign.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = 'Write a rock song about the Moon and a Raven.'\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07ad3d66-f4fc-45bb-b929-85bc23112294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "Beneath the midnight sky, a raven takes flight\n",
      "Against the glowing moon, a haunting sight\n",
      "Its feathers black as coal, its eyes piercing and bright\n",
      "A messenger of mystery, a creature of the night\n",
      "\n",
      "Chorus:\n",
      "Oh moon and raven, dance in the pale moonlight\n",
      "A symphony of darkness, a duet of the night\n",
      "Oh moon and raven, shadows intertwined\n",
      "A love affair of secrets, a bond that's undefined\n",
      "\n",
      "Verse 2:\n",
      "The raven calls out, a mournful cry\n",
      "Echoing through the stillness of the night sky\n",
      "The moon watches silently, casting its soft light\n",
      "A silent witness to the raven's plight\n",
      "\n",
      "Chorus:\n",
      "Oh moon and raven, dance in the pale moonlight\n",
      "A symphony of darkness, a duet of the night\n",
      "Oh moon and raven, shadows intertwined\n",
      "A love affair of secrets, a bond that's undefined\n",
      "\n",
      "Bridge:\n",
      "In the darkness they find solace\n",
      "In the stillness they find peace\n",
      "The moon and the raven, two creatures of the night\n",
      "Bound together in the darkness, their spirits taking flight\n",
      "\n",
      "Chorus:\n",
      "Oh moon and raven, dance in the pale moonlight\n",
      "A symphony of darkness, a duet of the night\n",
      "Oh moon and raven, shadows intertwined\n",
      "A love affair of secrets, a bond that's undefined\n",
      "\n",
      "Outro:\n",
      "As the night fades away, the moon and raven depart\n",
      "But in the shadows they'll always remain, forever in each other's heart\n",
      "A tale of mystery and magic, a bond that will never die\n",
      "The moon and the raven, forever soaring high."
     ]
    }
   ],
   "source": [
    "### Enable streaming\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1aa03-2784-4ba0-ae56-d9a8fb62f83d",
   "metadata": {},
   "source": [
    "### PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92db81fe-dd60-44ff-8555-f66ab513c823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an experience virologist. Write a few sentences about the following virus \"hiv\" in german.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = '''You are an experience virologist. Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.format(virus='hiv', language='german')\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f5a42fb-7780-4cdf-a3c8-d83011e4b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV, das humane Immundefizienzvirus, ist ein Virus, das das Immunsystem des Menschen schwächt und zu AIDS führen kann. Es wird hauptsächlich durch ungeschützten Geschlechtsverkehr, den Austausch von infizierten Nadeln oder von der Mutter auf das Kind während der Schwangerschaft übertragen. Es ist wichtig, sich über die Übertragungswege und Präventionsmaßnahmen von HIV zu informieren, um die Verbreitung dieser lebensbedrohlichen Krankheit einzudämmen.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc554a1-2b75-4de4-9042-cd476bdb89f3",
   "metadata": {},
   "source": [
    "### ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec0651ea-cd9b-46bc-9833-3888a135f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format.'), HumanMessage(content='Top 10 countries in World by population.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in the JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n='10', area='World')\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7537eef6-d1e2-4091-a38e-b879647d2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"countries\": [\n",
      "        { \"rank\": 1, \"country\": \"China\", \"population\": 1439323776 },\n",
      "        { \"rank\": 2, \"country\": \"India\", \"population\": 1380004385 },\n",
      "        { \"rank\": 3, \"country\": \"United States\", \"population\": 331002651 },\n",
      "        { \"rank\": 4, \"country\": \"Indonesia\", \"population\": 273523615 },\n",
      "        { \"rank\": 5, \"country\": \"Pakistan\", \"population\": 220892331 },\n",
      "        { \"rank\": 6, \"country\": \"Brazil\", \"population\": 212559417 },\n",
      "        { \"rank\": 7, \"country\": \"Nigeria\", \"population\": 206139589 },\n",
      "        { \"rank\": 8, \"country\": \"Bangladesh\", \"population\": 164689383 },\n",
      "        { \"rank\": 9, \"country\": \"Russia\", \"population\": 145934462 },\n",
      "        { \"rank\": 10, \"country\": \"Mexico\", \"population\": 128932753 }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5af936-da6b-40a7-a05a-46cb202ebef8",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c51835d8-fb03-44c6-ad67-4ec2e15d295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasyidannas/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'language'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template\u001b[38;5;241m=\u001b[39mtemplate)\n\u001b[1;32m      9\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     10\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     11\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt_template\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvirus\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHSV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlangugae\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndonesian\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:151\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    146\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m     inputs,\n\u001b[1;32m    148\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:279\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    277\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'language'}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "template = '''You are an experience virologist. Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "output = chain.invoke({'virus': 'HSV', 'language': 'Indonesian'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0615d5c4-5331-4cb4-b8bc-e22e4ac3d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n    \"countries\": [\\n        { \"rank\": 1, \"country\": \"China\", \"population\": 1439323776 },\\n        { \"rank\": 2, \"country\": \"India\", \"population\": 1380004385 },\\n        { \"rank\": 3, \"country\": \"United States\", \"population\": 331002651 },\\n        { \"rank\": 4, \"country\": \"Indonesia\", \"population\": 273523615 },\\n        { \"rank\": 5, \"country\": \"Pakistan\", \"population\": 220892331 },\\n        { \"rank\": 6, \"country\": \"Brazil\", \"population\": 212559417 },\\n        { \"rank\": 7, \"country\": \"Nigeria\", \"population\": 206139589 },\\n        { \"rank\": 8, \"country\": \"Bangladesh\", \"population\": 164689383 },\\n        { \"rank\": 9, \"country\": \"Russia\", \"population\": 145934462 },\\n        { \"rank\": 10, \"country\": \"Mexico\", \"population\": 128932753 }\\n    ]\\n}' response_metadata={'token_usage': {'completion_tokens': 235, 'prompt_tokens': 28, 'total_tokens': 263}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-c235e8e2-3744-4b15-b6a4-9d4f62f3e300-0'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb32c90-c28a-4068-adcd-1756f3d0860f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
